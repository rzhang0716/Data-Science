{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_intro_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)"
      ],
      "metadata": {
        "id": "_nNeDqXu2dbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-oE_Ii2CWVRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc3828e-8c28-4c79-e661-e26efe0aca65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-c33728af-2221-a1a1-af19-c36f1d41ac02)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Helper Functions"
      ],
      "metadata": {
        "id": "qwwtWlqx2c_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5xNYkY3LiM",
        "outputId": "0d546c13-a75f-4134-a8ff-f7d9a29eb307"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 14:13:20--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-04 14:13:20 (41.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep\n",
        "\n",
        "## Download a text dataset"
      ],
      "metadata": {
        "id": "91GBwNUw3RCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrV13yvy3QPq",
        "outputId": "c6c7dd16-3b3b-41f4-b4d8-f9a30c55f567"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 14:13:23--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-05-04 14:13:24 (98.4 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset"
      ],
      "metadata": {
        "id": "LH6W6PgF3ilq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kedq5cEo3k_7",
        "outputId": "9f1c8008-07a6-42a4-ae1c-13e39f5cb843"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-289fe253-6eda-4432-bee5-c1e5599cc6fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-289fe253-6eda-4432-bee5-c1e5599cc6fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-289fe253-6eda-4432-bee5-c1e5599cc6fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-289fe253-6eda-4432-bee5-c1e5599cc6fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i4Yf-zHf3rvJ",
        "outputId": "164c30ba-3d00-493d-90b4-bc72ac1f6b9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7ad402f-50c8-49ac-8f64-d016a21d7a29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7ad402f-50c8-49ac-8f64-d016a21d7a29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7ad402f-50c8-49ac-8f64-d016a21d7a29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7ad402f-50c8-49ac-8f64-d016a21d7a29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The test data doesn't have a target\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0Y9W7IZV35MY",
        "outputId": "a0ee92b5-08b1-4460-b0df-8e6aedec7bdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4d79ada-2ba3-47c7-b334-8873f4660bb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4d79ada-2ba3-47c7-b334-8873f4660bb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4d79ada-2ba3-47c7-b334-8873f4660bb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4d79ada-2ba3-47c7-b334-8873f4660bb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyw9k-e4J2r",
        "outputId": "20415ec8-f31d-4d77-80c2-f38d23689c3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKZTm_uv4ON-",
        "outputId": "e3cd8b08-c147-4ea6-f082-47840b52b252"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into training and validation sets"
      ],
      "metadata": {
        "id": "x6JIjpd747kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility\n",
        "\n",
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34iOcKEK41rF",
        "outputId": "ec1f503c-ee1a-4951-b7da-88dc5c5a0264"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. Three levels of tokenization:\n",
        "\n",
        "  a. **word-level tokenization**, every word in a sequence considered a single token.\n",
        "  \n",
        "  b. **Character-level tokenization**, every character in a sequence considered a single token.\n",
        "  \n",
        "  c. **Sub-word tokenization**, breaking individual words into smaller parts and then converting those smaller parts into numbers.\n",
        "\n",
        "* **Embeddings**- An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector.\n",
        "\n",
        "  a. **Creating own embedding** - Once text has been turned into numbers (required for an embedding), put them through an embedding layer (`tf.keras.layers.Embedding`) and the embedding representation will be learned during model training.\n",
        "\n",
        "  b. **Reuse a pre-learned embedding** - There are many pre-trained embeddings exis online, these embeddings have often been learned on large corpuses of text and thus have a good underlying representation of natural language. Use a pre-trained embedding to initialize the model and fine-tune it to the specific task."
      ],
      "metadata": {
        "id": "E1Hl9nrd5bl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "To tokenize our words, we'll use the helpful preprocessing layer `tf.keras.layers.experimental.preprocessing.TextVectorization`.\n",
        "\n",
        "The TextVectorization layer takes the following parameters:\n",
        "\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* `standardize` - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is \"whitespace\" which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n",
        "* `output_mode` - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."
      ],
      "metadata": {
        "id": "l9q5DaXC8xuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization"
      ],
      "metadata": {
        "id": "56nZpwTr-xI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens"
      ],
      "metadata": {
        "id": "Mx-7xvQy5Shu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPKGPwvY-q72",
        "outputId": "fcd1d3f1-12cf-45bf-c3a7-85c9057de602"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "1r8o3-e--3Q9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "ao9l_n70_EBG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQgXof___Zjc",
        "outputId": "2e5332aa-66f6-439d-d10f-89e1da346811"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzRcYIBn_j68",
        "outputId": "deb436da-f9db-41de-a35e-137f53625449"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "If Trillion crosses the line a 3rd time he does a field-wide attack that does instant kill damage      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  47, 4376, 3960,    2,  648,    3, 3207,   92,   56,  350,    3,\n",
              "           1,  113,   16,  350]])>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-LzqqIe__NM",
        "outputId": "216a959b-9ce7-4bb2-b930-bc3e65ed51cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "* `input_dim` - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "\n",
        "* `input_length` - Length of sequences being passed to embedding layer."
      ],
      "metadata": {
        "id": "YLC3qE5aAPOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, initialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIhUov8ZAMpm",
        "outputId": "c6ab93a3-684c-4ce8-f370-750dba78eefd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fdc50140ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--cUK1OwCBcx",
        "outputId": "6326ac82-f92b-4e7a-f25b-8c684526e3e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Evacuation order lifted for Roosevelt after #Wildfire misses town - KOMO News http://t.co/qCpMktGLLR      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02939058, -0.04368952,  0.01358509, ..., -0.03002634,\n",
              "         -0.02905551,  0.02413115],\n",
              "        [ 0.01532686,  0.01324354,  0.02279527, ...,  0.02718167,\n",
              "          0.04858797,  0.04597837],\n",
              "        [ 0.0352683 ,  0.0164617 , -0.04468585, ...,  0.02107281,\n",
              "         -0.02031373,  0.027226  ],\n",
              "        ...,\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data"
      ],
      "metadata": {
        "id": "dI4J_u3jDZEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Getting a baseline"
      ],
      "metadata": {
        "id": "LHPATZn7EEim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNaxD8OQCCnf",
        "outputId": "a8c6a71e-9818-4c0b-8fd3-7e49c20edc70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(baseline_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMR-odK7G_Xr",
        "outputId": "52a16839-fe5c-4856-e573-d91c5f6a8196"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7926509186351706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgZMrKtdIePI",
        "outputId": "f3fbd325-64b5-4fdc-df5b-b38923787d93"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "2jyDRIlxJPs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "tfD9oJphIlh6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6QqHENtJkhE",
        "outputId": "0cf60613-bb9e-48ff-8da8-bdf7a74ad1ff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "QKpRW1gMKNT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "fl84hn8RJlpH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
        "\n",
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhioKOFWK8HH",
        "outputId": "19d60bb9-a21c-48ce-dbf5-a79b03d827b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20220504-141329\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 7ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jKcJiSZMC-W",
        "outputId": "646db497-6215-46eb-81bc-b0f7161401b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47668465971946716, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"First deep model on text data\" \\\n",
        "#   --description \"Trying a dense model with an embedding layer\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ],
      "metadata": {
        "id": "6f7WspJ_MGjR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))"
      ],
      "metadata": {
        "id": "6eV2tKikNJxC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the model_1_metrics\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7jhy7ppNo-S",
        "outputId": "f97b1d02-3a80-46f2-c080-6fac22e8a47e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7846966492209201,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjRg0BZAN8CW",
        "outputId": "d0f0d562-c180-4c3e-a1d3-37c1a5ab6e13"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing learned embeddings"
      ],
      "metadata": {
        "id": "uuAvD1b-OD_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "\n",
        "# Get the weight matrix of embedding layer\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkn3H4SUN-Tu",
        "outputId": "02521026-38a5-4702-e5f6-d91bb2c06889"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num == 0: \n",
        "#      continue # skip padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "8s0NjMBsOjCr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once you've downloaded the embedding vectors and metadata, you can visualize them using Embedding Vector tool:\n",
        "\n",
        "1. Go to http://projector.tensorflow.org/\n",
        "2. Click on \"Load data\"\n",
        "3. Upload the two files you downloaded (embedding_vectors.tsv and embedding_metadata.tsv)\n",
        "4. Explore\n",
        "5. Optional: You can share the data you've created by clicking \"Publish\""
      ],
      "metadata": {
        "id": "XAvY1pHpOqZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: RNN - LSTM\n",
        "\n",
        "Main difference is to add an LSTM layer between embedding and output."
      ],
      "metadata": {
        "id": "b17V8CXlSQ0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layer.LSTM(64, return_sequence=True)(x) # Return vector for each word in the Tweet, stack RNN cells to keep same dimension\n",
        "x = layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])\n",
        "\n",
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "\n",
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "\n",
        "\n",
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "\n",
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1EdfAhjOpg4",
        "outputId": "4382cdda-06b2-438b-948f-4e953eec1446"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n",
            "Saving TensorBoard log files to: model_logs/LSTM/20220504-141343\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 19ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n",
            "Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n",
            "Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n",
            "Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n",
            "Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: RNN - GRU"
      ],
      "metadata": {
        "id": "FTKBAEUGVjxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "\n",
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])\n",
        "\n",
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]\n",
        "\n",
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]\n",
        "\n",
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results\n",
        "\n",
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjBDI2yMUqCS",
        "outputId": "7f9e5f2e-cb2c-4aeb-94d2-d32fdb9fb64e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20220504-141410\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 12ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n",
            "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Bidirectional RNN model"
      ],
      "metadata": {
        "id": "81yoAsE1W4kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")\n",
        "\n",
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()\n",
        "\n",
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])\n",
        "\n",
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]\n",
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]\n",
        "\n",
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results\n",
        "\n",
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0jGDEbUW3Xd",
        "outputId": "11ac2590-a82a-4dad-a2f4-e8b588dc39d5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20220504-141434\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 19ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n",
            "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: CNN for Text --- Conv1D"
      ],
      "metadata": {
        "id": "VLczJHGtXNE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn into embedded words\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over tager sequnece 5 word a time\n",
        "conv_1d_output = conv_1d(embedding_test)  # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most import features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEFZ71NCXL8a",
        "outputId": "2211e031-5daf-451a-a3b4-0a92912a5fb6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "print(model_5.summary())\n",
        "\n",
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])\n",
        "\n",
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]\n",
        "\n",
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]\n",
        "\n",
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results\n",
        "\n",
        "# Compare model_5 results to baseline \n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "id": "0LMmSUeHYuCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c294b3-168a-4719-c4b0-e0c3a4fc3b58"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Saving TensorBoard log files to: model_logs/Conv1D/20220504-141840\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 9ms/step - loss: 0.5652 - accuracy: 0.7141 - val_loss: 0.4733 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.4758 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.5457 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1314 - accuracy: 0.9578 - val_loss: 0.6163 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.6779 - val_accuracy: 0.7782\n",
            "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: Using Pretrained Sentence Encoder from TensorFlow Hub"
      ],
      "metadata": {
        "id": "H4bN7g_PcAK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with universal sentence encoder\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFjD-ytJa0_j",
        "outputId": "7ed395f3-33ba-40e5-9942-0fa5c8bf60ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "u_jPGO3tevZl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCHE_vLae8pi",
        "outputId": "44fed38f-4595-4c65-94ac-3d732128b0ff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i99WE8vfBGW",
        "outputId": "720d2e86-5390-4560-ca5e-d7669b6eedd8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220504-143205\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 26ms/step - loss: 0.5008 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 0.4144 - accuracy: 0.8133 - val_loss: 0.4369 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 7s 30ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.4329 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.3925 - accuracy: 0.8266 - val_loss: 0.4288 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.4309 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]\n",
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]\n",
        "\n",
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results\n",
        "\n",
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-jpnheEfDk2",
        "outputId": "0bf09800-e9ea-4279-e8a9-a83ec7adbd63"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.23, Difference: 1.97\n",
            "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
            "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Performance"
      ],
      "metadata": {
        "id": "gQ3YtNlRfSVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Kv-dkIunfL_5",
        "outputId": "f4a3c3b8-503f-494b-c75e-1f2cb52d89fa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
              "lstm                     75.065617   0.751008  0.750656  0.748927\n",
              "gru                      76.771654   0.767545  0.767717  0.766793\n",
              "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
              "conv1d                   77.821522   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  81.233596   0.814880  0.812336  0.810687"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f2a228a-dd7a-41af-9dd8-266d4d7bbcb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.740157</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2a228a-dd7a-41af-9dd8-266d4d7bbcb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f2a228a-dd7a-41af-9dd8-266d4d7bbcb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f2a228a-dd7a-41af-9dd8-266d4d7bbcb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "\n",
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "oiACWtjffXmF",
        "outputId": "8bace37d-2eab-49bc-d638-3ee3335273f9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "PfNn5qH-favi",
        "outputId": "975570fb-0fc8-4baf-d088-56c7762a8346"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining our models (ensembling/stacking)\n",
        "\n",
        "Many production systems use an ensemble (multiple different models combined) of models to make a prediction.\n",
        "\n",
        "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
        "\n",
        "The keyword in the sentence above is uncorrelated, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
        "\n",
        "1. Averaging - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n",
        "2. Majority vote (mode) - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict [1, 0, 1] respectively, the majority class is 1, therefore, that would be the predicted label.\n",
        "3. Model stacking - Take the outputs of each of your chosen models and use them as inputs to another model."
      ],
      "metadata": {
        "id": "FmnrY3JLfgCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean pred probs for 3 models\n",
        "import numpy as np\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]                                                                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS2chFXhi_x_",
        "outputId": "db1a2f7a-9649-454c-eded-5307179518c4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GJ0LeVLk11h",
        "outputId": "f145a365-5351-4f89-d8c9-98d2004a91e4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1': 0.7805169025578647,\n",
              " 'precision': 0.7805216999297674,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results\n",
        "\n",
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n",
        "\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "7LSAutMlmqho",
        "outputId": "cbf5720d-8700-4868-89b6-b6e09018241d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.787402   0.791492  0.787402  0.784697\n",
              "lstm                     0.750656   0.751008  0.750656  0.748927\n",
              "gru                      0.767717   0.767545  0.767717  0.766793\n",
              "bidirectional            0.766404   0.766590  0.766404  0.765121\n",
              "conv1d                   0.778215   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  0.812336   0.814880  0.812336  0.810687\n",
              "ensemble_results         0.780840   0.780522  0.780840  0.780517"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd96b1e8-eb86-4583-93dd-5ab030184abb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780522</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd96b1e8-eb86-4583-93dd-5ab030184abb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd96b1e8-eb86-4583-93dd-5ab030184abb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd96b1e8-eb86-4583-93dd-5ab030184abb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjs_TcuLmuQA",
        "outputId": "66125413-02c6-4acf-de7e-24e5ea984f4b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.17589059472084045\n",
            "Text:\n",
            "@maeisdumb WHOAHAHAHAHHDJS electrocute me....\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8596510887145996\n",
            "Text:\n",
            "Birmingham Wholesale Market is ablaze BBC News - Fire breaks out at Birmingham's Wholesale Market http://t.co/irWqCEZWEU\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.03797103464603424\n",
            "Text:\n",
            "#FatLoss #Diet How Can You Find The Best Ways To Reduce Weight? http://t.co/czcC7NIEoX #Thunder #Health\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8123064041137695\n",
            "Text:\n",
            "Sinai branch of Islamic State threatens to execute Croatian hostage in 48 hours http://t.co/YvtcXrPt34\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8118816614151001\n",
            "Text:\n",
            "#USGS M 1.9 - 15km E of Anchorage Alaska: Time2015-08-06 00:11:16 UTC2015-08-05 16:11:16 -08:00 at epicen... http://t.co/HkIiPyX5jL #SM\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8472799062728882\n",
            "Text:\n",
            "Important piece on long-term #health effects of #Hiroshima by @juliepower: http://t.co/J2s4Ng7wGt via @smh @croakeyblog\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.1420004963874817\n",
            "Text:\n",
            "I've had electrical tape wrapped around my charger for like 2 months bc I don't want to get electrocuted :))))) http://t.co/Fb3Do910FC\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.2560351490974426\n",
            "Text:\n",
            "We are now up to run no. 24 in the singles. The rain has blown off again.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.31850680708885193\n",
            "Text:\n",
            "Politifiact: Harry Reid's '30 Percent of Women Served' Planned Parenthood Claim Is a 'Pants on Fire' Lie: Call... http://t.co/wY4Xu1A9j4\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.305359423160553\n",
            "Text:\n",
            "Greece's tax revenues collapse as debt crisis continues http://t.co/V5yyzNGRBZ\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DZp-CfQFm1lk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}