\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amsmath, amsfonts}
\usepackage{etoolbox}
\usepackage{algorithmicx}



\title{CS4780/5780 Homework 1}
\author{Due: Tuesday 02/13/2018 11:55pm on Gradescope}
\date{}
\begin{document}
	\maketitle
	\noindent
	\textbf{Note: For homework, you can work in a team of 5. Please include your teammates' NetIDs and names on the front page and form a group on Gradescope. Also, you are given two late days for this homework.}
	\section*{Problem 1: Train/Test Splits}
	\begin{enumerate}
		\item Suppose your boss Chris asks you to develop a Machine Learning application that could identify the phonemes (the basic sound units) despite different speakers. The dataset is a series of recordings on how different people pronounce the 44 phonemes with the following properties:
		\begin{itemize}
			\item Each recording is associated with only one phoneme and person.
			\item The recordings are from 100 people.
			\item The data collection is done in a week. In that week, all the participants come in for 5 days (Monday to Friday) to create the recordings.
			\item Each person records around 200 phonemes per day. 
		\end{itemize}
		Armed with the knowledge you learned in class, you know that you can frame this problem as a supervised learning problem. Devise a valid scheme to split the dataset into training, validation and test sets. 
		\item After you deploy the application, Kilian says the application is not able to identify phonemes from his voice. In order to develop a phoneme identification system that will work exclusively on him, he is willing to invest an enormous amount of money and sends in 10000 recordings of him pronouncing different phonemes. In this case, how would you split the dataset into training, validation and test set? Please assume you have to include the dataset from problem 1 part 1 when you train your model.
	\end{enumerate}
	
%	Suppose you are working with a team to develop a Machine Learning algorithm to identify patients who are at high risk of developing brain cancer within a year. Your dataset is the patients' medical history and the result of their neurological exams with the following properties:
%	\begin{itemize}
%		\item All the data is collected in January and each record will be labeled as either positive or negative. A record is labeled as positive if the patient is diagnosed with brain cancer from February till the end of the year and negative otherwise.
%		\item The data is collected in 2016 and 2017. You know the year each record is collected.
%		\item Each patient can only contribute a record to the dataset.
%	\end{itemize}
%	%%%%%%%%%%%%%%%%%%%
%	%%%%%%%%%%%%%%%%%%%	
	
	
	
%	One of your teammates suggested that you should split the dataset in the following way: Use 80\% of the records from each year to form the training set, 10\% of the records from each year as the validation set and the rest as the test set. Do you think his/her suggestion is reasonable? If yes, explain your reasoning. If no, come up with a new train/test split setup and explain why your setup is better.
%	
%	
	
	\section*{Problem 2: K-nearest Neighbors}
	\begin{enumerate}
		\item Consider you have the following 2D dataset:
			\begin{itemize}
				\item Positive: $\{(1, 2), (1, 4), (5,4)\}$
				\item Negative: $\{(3, 1), (3, 2)\}$
			\end{itemize}
			Suppose the data comes from the grid $[0, 5] \times [0, 5]$. Draw the decision boundary for 1-NN classifier with the Euclidean distance. 
		\item Consider you have the following 2D dataset:
			\begin{itemize}
				\item Positive: $\{(100, 2), (100, 4), (500,4)\}$
				\item Negative: $\{(300, 1), (300, 2)\}$
			\end{itemize}
		Suppose the data lies in the grid $[0, 500] \times [0, 5]$. If you use a 1-NN classifier (assume Euclidean distance), will the classifier be able to classify $(500, 1)$ as negative? One of the problems with using Euclidean distance is that when we have features of different scales, the Euclidean distance will be dominated by the features that have larger scales. One way to fix this is to scale all the features linearly to $[0,1]$. Will a 1-NN classifier be able to classify $(500, 1)$ as negative after we scale the features linearly to $[0,1]$?
		\item K-NN can also be used for regression (meaning, your labels are real values now). Suppose you have the following dataset: 
		\begin{center}
			\begin{tabular}{|c|c|}
				\hline
				$\mathcal{X}$ & $\mathcal{Y}$ \\
				\hline
				 (0,0) & 1 \\
				 (1,1) & 2 \\
				 (2,3) & 3 \\
				 (3,1) & 1 \\
				 (2,1) & 2 \\
				 \hline
			\end{tabular}
		\end{center}
		where $\mathcal{X}$ is the feature and $\mathcal{Y}$ is the label. What would be the label for $(0,1)$ if we use 2-NN with Euclidean distance?
		\item Real world datasets often have missing values for certain features. Can we still use K-NN on these datasets? If yes, explain how.   
		\item Does it take more time to train a K-NN classifier or to apply a K-NN classifier? Explain your reasoning. (Please assume that the data is on the magnitude of millions of points).
		\item K-NN classifiers are known to suffer from the curse of dimensionality. However, in class we showed that K-NN actually works on images which are often high dimensional. Explain why.
		
		
%		Which of the following way(s) can help boost the accuracy of K-NN classifiers in high dimensional spaces?
%		\begin{enumerate}
%			\item Use dimensionality reduction methods to reduce the dimensionality of the dataset. (Note: we will not cover dimensionality reduction in this class. If you are interested, this topic is taught in CS4786)
%			\item Increase the size of the dataset.
%			\item Use parallel computing. 
%		\end{enumerate}
	\end{enumerate}
	
%	\section*{Problem: Estimating Probabilities from data}
%	Suppose you have a dataset $\mathcal{D} = \{\bar{x}_i\}_{i=1}^n \in \mathbb{R}^d$. Each data point $\bar{x}_i$ that is drawn independently from $\mathcal{N}(\mu, I)$ where $I$ is the $d \times d$ identity matrix.
%	\begin{enumerate}
%		\item Find the MLE for $\mu$.
%		\item Assume a standard Gaussian prior on $u$, namely, $P(u) = \mathcal{N}(0, I)$, find the MAP for $\mu$.
%		\item Again, assume a the same Gaussian prior on $u$ in (2), find the posterior $P(\mu | \mathcal{D})$. (Hint: the posterior is a Gaussian distribution.)
%	\end{enumerate}
%	
%	\newpage
%
%	\section*{Problem: Logistic Regression}
%	In this problem, we are going to assume the same notation setup in class. For logistic regression, we model the class probability by 
%	
%	$$P(y|\vec{x_i}) = \sigma(y(\vec{w}^T\vec{x} + b))$$ where we define 
%	
%	$$\sigma(s) = \frac{1}{1 + e^{-s}}$$
%	
%	\begin{enumerate}
%		\item Show that the sigmoid function $\sigma(\cdot)$ has the following property $$\sigma(-s) = 1 - \sigma(s)$$ By proving this property, we have shown that we have properly defined a probabilistic model, namely, $P(y_i = 1| \vec{x_i}) + P(y_i = 1| \vec{x_i}) = 1$  
%		\item In class, we mentioned about using Gradient Descent to find the MLE estimate for $\vec{w}$. One of the problems with Gradient Descent is that the algorithm sometimes gets stuck at a local optima rather than the global optima. In this question, we are going to show that for logistic regression, Gradient Descent always return the global optima. 
%		\begin{enumerate}
%			\item To make things easier, first show that $$\sigma'(s) = \sigma(s) (1-\sigma(s))$$
%			\item Find the gradient of the log likelihood function, namely, $\nabla_w P(\vec{y} | X, \vec{w})$.
%			\item Find the Hessian $H$ of the log likelihood function.
%			\item Show that the Hessian is negative semi-definite, namely, $\vec{z}^TH\vec{z} \leq 0$ for any vector $\vec{z} \in \mathbb{R}^d$. By showing this, we have shown that the negative log likelihood is concave and has no local maxima except the global one. 
%		\end{enumerate}
%	\end{enumerate}
	
	
%	
%	\section*{Problem 6: Linear Regression}
%	
%	\section*{Problem 7: Linear SVM}
%%	

	
%	\begin{algorithmic}
%		\If{lala} 
%		\EndIf
%	\end{algorithmic} 
%	
%	\section*{Problem 9: AdaBoost}
%	
%	\section*{Problem 10: Deep Learning}
\end{document}