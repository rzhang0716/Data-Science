# -*- coding: utf-8 -*-
"""00_tensorflow_fundamentals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P779PTuUrnkdKEIi8rmvCTh03HSBCz4l

# Introduction to Tesnors
"""

# Import TensorFlow
import tensorflow as tf
print(tf.__version__)

# Create tensors with tf.constant()
scalar = tf.constant(7)
scalar

# Check the number of dimensions of a tensor (ndim stands for number of dimensions)
scalar.ndim

# Create a vector
vector = tf.constant([10, 10])
vector

# Check the dimension of vector
vector.ndim

# Create a matrix (has more than one dimension)
matrix = tf.constant([[10,7],[7,10]])
matrix

matrix.ndim

# Create another matrix
another_matrix = tf.constant([[10., 7.],
                              [3., 2.],
                              [8., 9.]], dtype=tf.float16) # specify the data type with dtype parameter
another_matrix

# What is the number of dimension of another_matrix?
another_matrix.ndim

# Let's create a tensor
tensor = tf.constant([[[1,2,3],
                       [4,5,6]],
                       [[7,8,9],
                       [10,11,12]],
                       [[13,14,15],
                        [16,17,18]]])
tensor

tensor.ndim

"""# Creating tensors with `tf.Varaibles`"""

# Create the same tensor with tf.Varaible() as above
changeable_tensor = tf.Variable([10, 7])
unchangeable_tensor = tf.constant([10, 7])
changeable_tensor, unchangeable_tensor

# Change one of elements in tensor
changeable_tensor[0].assign(7)
changeable_tensor

"""# Creating random tensors

Random tensors are tensors of some arbitrary size which contain random numbers
"""

# Create two random (but the same) tensors
random_1 = tf.random.Generator.from_seed(42)
random_1 = random_1.normal(shape=(3,2))
random_1

random_2 = tf.random.Generator.from_seed(42)
 random_2 = random_2.normal(shape=(3,2))
 random_2

random_1 == random_2

"""# Shuffle the order of elements in a tensor"""

# Shuffle a tensor (Valuable for when you want to shuffle your data so the inherent order doesn't affect learning)
not_shuffled = tf.constant([[10,7],
                           [3,4],
                           [2,5]])
not_shuffled.ndim

# Shuffle our non-shuffled tensor
tf.random.set_seed(42) # global level seed
tf.random.shuffle(not_shuffled, seed=42) # operational level seed

"""# Creating tensors from Numpy arrays"""

# CREATE a tensor of all ones
tf.ones([10,7])

# Create a tensor of all zeros
tf.zeros(shape=(3,4))

"""The main difference between numpy array and tensorflow tensors is that tensors can be run on a GPU (much faster for numeical computing)."""

# Turn numpy array to tensors
import numpy as np
numpy_A = np.arange(1,25, dtype=np.int32) # create a Numpy array between 1 and 25

# X = tf.constant(some_matrix) # Capital for matrix or tensor
# y - tf.constan(vector) # Non-capital for vector

A = tf.constant(numpy_A, shape=(2,3,4))
A

"""# Getting information from Tensors"""

# Create a rank 4 tensor(4 dimensions)
rank_4_tensor = tf.zeros(shape = [2,3,4,5])
rank_4_tensor

# Get various attributes of our tensor
print("Datatype of every element:", rank_4_tensor.dtype)
print("Number of dimensions (rank):", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along the 0 axis:", rank_4_tensor.shape[0])

"""# Indexing and expanding tensors"""

# Get the first 2 elements of each dimension; Same as list
rank_4_tensor[:2,:2,:2,:2]

# Get first element from each dimension from each index except for the final one
rank_4_tensor[:1,:1,:1]

# Create a rank 2 tensor (2 dimensions)
rank_2_tensor = tf.constant([[10,7],
                             [3,4]])
rank_2_tensor.shape

rank_2_tensor[:,-1]

# Add in extra dimension to our rank 2 tensor
rank_3_tensor = rank_2_tensor[...,tf.newaxis]

rank_3_tensor

# Alternative to tf.newaxis
tf.expand_dims(rank_2_tensor, axis=-1) # '-1' means expand the final axis

"""# Manipulating tensors with basic operations"""

rank_2_tensor + 10

"""# Matrix Multiplication"""

# Perform matrix mulplication betwen X and Y 
# #tf.reshape(X) 
# tf.transpose(X)

"""# Change teh data type of TensorFlow"""

# Create a new tensor with default datatype (float32)
B = tf.constant([1.7, 7.4])
B.dtype

# Change from float32 to float16

B = tf.cast(B, dtype=tf.float16)

B

"""# Aggregation Tensors

Aggregating tensors = condesing them from multiple values down to a small amount of values
"""

# Get the absolute values
D = tf.constant([-7, -10])
D
tf.abs(D)

# Create a random tenssor with values between 0 and 100 of size 50
E = tf.constant(np.random.randint(0,100, size=50))

tf.size(E), E.shape, E.ndim

# Find the minimum
tf.reduce_min(E)

# Find the maximum
tf.reduce_max(E)

# Find the mean
tf.reduce_mean(E)

# Find the sum
tf.reduce_sum(E)

# To find the variance
import tensorflow_probability as tfp
tfp.stats.variance(E)

# To find standard deviation (Has to be float)
tf.math.reduce_std(tf.cast(E, dtype=tf.float32))

"""# Find the position of minimum and maximum of a tensor"""

tf.random.set_seed(42)
F = tf.random.uniform(shape=[50])
F

# Find the positional maximum
print(tf.argmax(F))

# Index on our largest value position
F[tf.argmax(F)]

# Find the max 
tf.reduce_max(F)

"""# Squeezing a tensor (removing all single dimensions)"""

tf.random.set_seed(42)
G = tf.constant(tf.random.uniform(shape=[50]), shape=(1,1,1,1,50))
G

G_squeezed = tf.squeeze(G)
G_squeezed

"""# One-hot encoding tensors"""

# Create a list of indices
some_list = [0,1,2,3]

# One hot encoding 
tf.one_hot(some_list, depth=4)

"""# Tensors and Numpy"""

# Create a tensor directly from a Numpy Array
J = tf.constant(np.array([3.,7.,10.]))

# Convert our tensor to numpy array
np.array(J)
J.numpy()

"""# GPU"""

tf.config.list_physical_devices()

!nvidia-smi

