\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{mathabx}
\usepackage{tikz}

\setlength\parindent{0pt}

\title{CS 4780/5780 Homework 4\vspace{-10pt}}
\author{Due: Tuesday 03/06/18 11:55pm on Gradescope}
\date{\vspace{-20pt}}

\begin{document}
\maketitle

\section*{Problem 1: Intuition for naive Bayes}
Kilian loves carnivals and brings the whole class along for his yearly trip. His favorite game is the Coin Flippin' Extravaganza, and he proclaims that any student that can help him win will get an A in his heart. Can you help him beat the house?


\subsection*{a)}
The game starts simple. There is a red hat and a blue hat each with a weighted penny. The operator secretly selects a penny at random, flips it, and asks you to guess which hat it came from. Suppose you know that the red hat's penny is weighted to come up heads $3/5$ of the time, and the blue hat's penny is weighted to come up heads $7/10$ of the time. If the penny comes up heads, what is the probability that it came from the red hat?

\textbf{Solution:}
From Bayes Theorem, we have: $${P(y = R|x = H)} = \frac{P(x = H|y = R)P(y = R)}{P(x = H)}$$We can easily calculate $P(x = H|y = R)$ and $P(x = H)$: 

\begin{align*}
P(x = H|y = R) &= \frac{3}{5}  = 0.6\\
P(y = R) &= \frac{1}{2} = 0.5
\end{align*}

To calculate $P(x = H)$ we can use the law of total probability to get:

\begin{align*}
P(x = H) &= P(y = R)P(x = H|y = R) + P(\neg (y = R))P(x = H|\neg (y = R))\\
&= P(y = R)P(x = H|y = R) + P(y = B)P(x = H|y = B)\\ 
&= \Big(\frac{1}{2}\Big)\Big(\frac{3}{5}\Big) + \Big(\frac{1}{2}\Big)\Big(\frac{7}{10}\Big)
\end{align*}


Now we can calculate $P(y = R|x = H)$ to get: $$ \frac{6}{13} = 0.462$$

\subsection*{b)}
To get you hooked, the operator next makes the game more complex, but with easier odds. Each hat actually has a penny, a nickel, a dime, and a quarter -- all weighted. The operator secretly selects all the coins from one hat at random, flips them all, and asks you to guess which hat they came from. Suppose you know the the red hat's penny, nickel, dime, and quarter come up heads with probability $[3/5, 3/10, 1/2, 4/5]$, respectively, and the blue hat's coins have heads probabilities $[7/10, 1/5, 1/10, 2/5]$, respectively. If the coins come up $[H,H,T,H]$, what is the probability that they came from the red hat?


\textbf{Solution:}
We are trying to find: 
$$P(y = R | \vec{x} = [H,H,T,H])$$

Using Bayes' Theorem, we can have: 

\begin{align*}
     P(y = R|\vec{x} = [H,H,T,H]) &= \frac{P(\vec{x} = [H,H,T,H] | y = R) P(y=R)}{P(\vec{x} = [H,H,T,H])} \\
     &= \frac{P(\vec{x} = [H,H,T,H] | y = R) P(y=R)}{P(\vec{x} = [H,H,T,H] | y = R) P(y=R) + P(\vec{x} = [H,H,T,H] | y = B) P(y=B)} \\
     &= \frac{(\frac{3}{5} \times \frac{3}{10} \times \frac{1}{2} \times \frac{4}{5}) \times (\frac{1}{2})}{(\frac{3}{5} \times \frac{3}{10} \times \frac{1}{2} \times \frac{4}{5})  \times (\frac{1}{2}) + (\frac{7}{10} \times \frac{1}{5}
     \times \frac{9}{10} \times \frac{2}{5})  \times (\frac{1}{2}) } \\
     &= \frac{10}{17}
\end{align*}

\subsection*{c)}
We've been making the assumption that you somehow know the coins' weights. In fact, in the Coin Flippin' Extravaganza, the operator never reveals the weights! Instead, you've spent the whole day watching people play the game, recording the results below:
\begin{center}
\begin{tabular}{ c | c c c c | c }
 game & penny & nickel & dime & quarter & hat \\ 
 \hline
 1 & T & H & T & T & Red \\
 2 & T & T & H & T & Blue \\
 3 & T & H & T & H & Blue \\
 4 & H & H & H & T & Red \\
 5 & H & H & T & T & Red \\
 6 & T & T & H & H & Blue \\
 7 & H & H & T & T & Red \\
 8 & T & T & H & T & Blue \\
 9 & T & H & H & T & Blue \\
 10 & H & H & H & T & Red \\
 11 & T & T & H & T & Blue \\
 12 & T & H & H & T & Red \\
 13 & H & H & T & T & Red \\
 14 & T & T & H & H & Blue \\
 15 & T & H & H & T & Blue \\
 16 & T & T & H & H & Blue \\
 17 & H & T & H & H & Red \\
 18 & H & T & H & T & Blue
\end{tabular}
\end{center}

% Generated using:
% RED $[1/2, 4/5, 3/5, 3/10]$
% BLUE $[1/10, 2/5, 7/10, 1/5]$

Now if the coins come up $[H,H,T,H]$, what is the probability that they came from the red hat?


\textbf{Solution:} 

Since we are not given the probabilities of the coins outright, we have to estimate them. That is we can estimate them using MLE. Additionally, From Bayes' Theorem, we know that :

% \begin{align*}
% P(y = R|\vec{x} = [H,H,T,H]) &= \prod_{\alpha = 1}^{k}P(y = R| x_{\alpha} = j) \\
% &= \prod_{\alpha = 1}^{k}\frac{P(x_{\alpha} = j|y = R)P(y = R)}{P(x_{\alpha} = j)} \\
% &= \prod_{\alpha = 1}^{k}\frac{[\Hat{\theta}_{jR}]_{\alpha}\frac{1}{2}}{\frac{1}{2}[\Hat{\theta}_{jR}]_{\alpha} + \frac{1}{2}[\Hat{\theta}_{jB}]_{\alpha}} \\
% &= \prod_{\alpha = 1}^{k}\frac{[\Hat{\theta}_{jR}]_{\alpha}}{[\Hat{\theta}_{jR}]_{\alpha} + [\Hat{\theta}_{jB}]_{\alpha}}  \\
% \end{align*}

\begin{align*}
    P(y = R|\vec{x} = [H,H,T,H]) &= \frac{P(\vec{x} = [H,H,T,H] | y = R) P(y=R)}{P(\vec{x} = [H,H,T,H])} \\
     &= \frac{P(\vec{x} = [H,H,T,H] | y = R) P(y=R)}{P(\vec{x} = [H,H,T,H])} \\
    &= \frac{\prod_{\alpha = 1}^{k}[\Hat{\theta}_{jR}]_{\alpha}P(y = R)}{\prod_{\alpha = 1}^{k}[\Hat{\theta}_{jR}]_{\alpha}P(y=R) + \prod_{\alpha = 1}^{k}[\Hat{\theta}_{jB}]_{\alpha}P(y=B)} \\
    &= \frac{\prod_{\alpha = 1}^{k}[\Hat{\theta}_{jR}]_{\alpha}}{\prod_{\alpha = 1}^{k}[\Hat{\theta}_{jR}]_{\alpha} + \prod_{\alpha = 1}^{k}[\Hat{\theta}_{jB}]_{\alpha}}, \text{where $j \in [H,H,T,H]$}
\end{align*}

Now to estimate the probability of a feature $\alpha$ has value $j$ given the label is $c$, $[\Hat{\theta}_{jc}]_{\alpha}$:

\begin{align*}
[\Hat{\theta}_{jc}]_{\alpha} &= \frac{\sum_{i = 1}^{18}I(y_i = c)I(x_{ia} = j)}{\sum_{i=1}^{18}I(y_i = c)} \\
[\Hat{\theta}_{HR}]_{penny} &= \frac{3}{4} = 0.75 \\
[\Hat{\theta}_{HR}]_{nickel} &= \frac{7}{8} = 0.875 \\
[\Hat{\theta}_{TR}]_{dime} &= \frac{1}{2} = 0.5 \\
[\Hat{\theta}_{HR}]_{quarter} &= \frac{1}{8} = 0.125 \\
[\Hat{\theta}_{HB}]_{penny} &= \frac{1}{10} = 0.1 \\
[\Hat{\theta}_{HB}]_{nickel} &= \frac{3}{10} = 0.3 \\
[\Hat{\theta}_{TB}]_{dime} &= \frac{1}{10} = 0.1 \\
[\Hat{\theta}_{HB}]_{quarter} &= \frac{4}{10} = 0.4
\end{align*}


Finally, taking the products of the probabilities we get:
$$\frac{4375}{4503} = 0.972$$




\subsection*{d)}
The above problem is actually a naive Bayes problem with Bernoulli distributed features! To see this, define the feature space $\mathcal{X}$ and the label space $\mathcal{Y}$. Is the naive Bayes assumption valid for this problem? Why?

\textbf{Solution:}
Feature space $\mathcal{X} \in \{H,T\}^4$. Label space $\mathcal{Y} \in \{Red, Blue\}$. The naive bayes assumption is valid because any two coin flips are independent of each other given a label. 

\section*{Problem 2: Usefulness of naive Bayes}
We wish to learn a classifier from the following dataset, in order to sort future emails as spam emails or as emails pertaining to ham. The dataset contains 15 emails, 3 binary features for each email, and the binary label.
\begin{center}
\begin{tabular}{ c | c c c | c }
 id & has word "bacon" & from recognized IP & contains misspelled word & label \\ 
 \hline
 1 & 0 & 0 & 1 & spam \\
 2 & 0 & 0 & 1 & spam \\
 3 & 0 & 1 & 0 & spam \\
 4 & 0 & 0 & 1 & spam \\
 5 & 1 & 0 & 0 & spam \\
 6 & 0 & 1 & 0 & spam \\
 7 & 0 & 0 & 1 & spam \\
 8 & 0 & 1 & 1 & spam \\
 9 & 0 & 0 & 1 & spam \\
 10 & 0 & 0 & 1 & spam \\
 11 & 1 & 1 & 0 & ham \\
 12 & 1 & 1 & 1 & ham \\
 13 & 1 & 0 & 1 & ham \\
 14 & 1 & 0 & 1 & ham \\
 15 & 1 & 1 & 0 & ham
\end{tabular}
\end{center}
\subsection*{a)}
Let's start with a simple model, where for each combination of features there is some underlying probability that the email pertains to ham. Using maximum likelihood estimation, what is the probability that an email pertains to ham if its feature vector is $(0,0,1)$? What if the feature vector is $(1,1,1)$? Or $(1,0,0)$? How about $(0,0,0)$? Are any of the predictions undefined? Do any of them seem unreasonable? If so, why?

\textbf{Solution:}

MLE in this simple model is:

$$P(y | \vec{x}) = \frac{\sum_{i=1}^nI(\vec{x}_i = \vec{x} \wedge y_i = y)}{\sum_{i=1}^nI(\vec{x}_i = \vec{x})}$$

Now we can calculate:

\begin{align*}
P(y = ham | \vec{x} = [0,0,1]) &= 0\\
P(y = ham | \vec{x} = [1,1,1]) &= 1\\
P(y = ham | \vec{x} = [1,0,0]) &= 0 \\
P(y = ham | \vec{x} = [0,0,0]) &= undefined\\
\end{align*}

These predictions do not seem reasonable. In particular, the bacon feature seems highly predictive for the ham class, so one would expect a good model to predict that an email with a feature vector $[1,0,0]$ has at least \textit{some} probability of pertaining to ham. In addition to that, $(1,0,0)$ is unreasonable because it is more likely ham than spam, since the "bacon" feature is more predictive than the other features. 


\subsection*{b)}
Consider the following ideas for improving our model. For each one, explain why you think the idea would or would not help to make our predictions well-defined or more reasonable.
\begin{itemize}
\item Collect more emails for the training dataset.
\item Extract more features for each email.
\item Duplicate emails with uncommon combinations of features.
\item Make stronger assumptions in our generative model for the data.
\end{itemize}

\textbf{Solution:}

\begin{itemize}
    \item Help. Having more data will get our MLE estimates closer to the true population probabilities. In addition, if we manage to collect data for every combination of feature values, we would avoid undefined predictions.
    \item Not help. We may get more undefined predictions because, for each test point, it becomes more unlikely that we have a training example with the exact same combination of features.
    \item Not help. This would not introduce any “fresh” data into our training dataset, and it may inaccurately skew our estimates for the population probabilities.
    \item Help.  In machine learning, you have to make model assumptions if you want to be able to learn from data. In this case, by making stronger assumptions about the type of model which may have generated the data (and thereby reducing the number of candidate models), we need fewer data points to identify a reasonable model. 
\end{itemize}
\subsection*{c)}
Let's try the last idea and make stronger model assumptions. Specifically, let's make the naive Bayes assumption that feature values are independent given the labels. Model each conditional probability with a Bernoulli distribution. What is the probability that an email pertaining to ham has the feature vector $(1,0,1)$? (Hint: start by using MLE to estimate the probability that an email has the word "bacon" given that it pertains to ham.)

\textbf{Solution:}
We are trying to find:
$$P(y = ham | \vec{x} = [1,0,1])$$

This follows the same process as \emph{1.c} except now we estimate $\Hat{\pi}_{c}$.

Estimating $\Hat{\pi}_{ham}$ we get:

$$\Hat{\pi}_{ham} = \frac{1}{3}$$

After applying bayes rule we get:


$$P(y = ham | \vec{x} = [1,0,1]) = \frac{120}{169} = 0.71$$



\subsection*{d)}
Using the naive Bayes classifier with the distributions you found above, what is the probability that an email pertains to ham if its feature vector is $(0,0,1)$? What if the feature vector is $(1,1,1)$? Or $(1,0,0)$? How about $(0,0,0)$? Are any of the predictions undefined? Do any of them seem unreasonable? If so, why?

\textbf{Solution:}

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
     & spam & ham  \\
     \hline
     $[\Hat{\theta}_{1}]_{bacon}$ & $\frac{1}{10}$ & $\frac{5}{5}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{bacon}$ & $\frac{9}{10}$ & $\frac{0}{5}$ \\
     \hline
     $[\Hat{\theta}_{1}]_{IP}$ & $\frac{3}{10}$ & $\frac{3}{5}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{IP}$ & $\frac{7}{10}$ & $\frac{2}{5}$ \\
     \hline
     $[\Hat{\theta}_{1}]_{misspelled}$ & $\frac{7}{10}$ & $\frac{3}{5}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{misspelled}$ & $\frac{3}{10}$ & $\frac{2}{5}$ \\
     \hline
\end{tabular}
\end{center}

\begin{align*}
P(y = ham | \vec{x} = [0,0,1]) &= 0 \\
P(y = ham | \vec{x} = [1,1,1]) &= \frac{60}{67} = 0.896\\
P(y = ham | \vec{x} = [1,0,0]) &= \frac{80}{101} = 0.792\\
P(y = ham | \vec{x} = [0,0,0]) &= 0 \\
\end{align*}


$[0,0,1], [0,0,0]$ seem unreasonable because intuitively there should be \emph{some} probability that emails with these features pertain to ham. Encouragingly, all of these predictions are now defined. (Note: It is still possible for an unsmoothed naive Bayes classifier to have undefined predictions, though. Can you see why?)

\subsection*{e)}
Complete parts \textbf{c} and \textbf{d} above, this time using $+1$ additive smoothing when estimating the model parameters. (Fun fact: this is effectively doing MAP estimation with a Beta prior distribution.) Do any of the predictions change? Do the probabilities? 

\textbf{Solution:}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
     & spam & ham  \\
     \hline
     $[\Hat{\theta}_{1}]_{bacon}$ & $\frac{2}{12}$ & $\frac{6}{7}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{bacon}$ & $\frac{10}{12}$ & $\frac{1}{7}$ \\
     \hline
     $[\Hat{\theta}_{1}]_{IP}$ & $\frac{4}{12}$ & $\frac{4}{7}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{IP}$ & $\frac{8}{12}$ & $\frac{3}{7}$ \\
     \hline
     $[\Hat{\theta}_{1}]_{misspelled}$ & $\frac{8}{12}$ & $\frac{4}{7}$ \\
     \hline
     $[\Hat{\theta}_{0}]_{misspelled}$ & $\frac{4}{12}$ & $\frac{3}{7}$ \\
     \hline
\end{tabular}
\end{center}

Estimation with +1 additive smoothing with 2 categories is as follows:

 $$[\Hat{\theta}_{jc}]_{\alpha} = \frac{\sum_{i = 1}^{18}I(y_i = c)I(x_{ia} = j) + 1}{\sum_{i=1}^{18}I(y_i = c) + 2}$$
 
 Now recalculating the probabilities we get:
 
 

\begin{align*}
P(y = ham | \vec{x} = [1,0,1]) &= \frac{486}{829} = 0.586 \\ 
P(y = ham | \vec{x} = [0,0,1]) &= \frac{81}{1796} = 0.045 \\
P(y = ham | \vec{x} = [1,1,1]) &= \frac{1296}{1639} = 0.791 \\ 
P(y = ham | \vec{x} = [1,0,0]) &= \frac{729}{1072} = 0.680\\
P(y = ham | \vec{x} = [0,0,0]) &= \frac{243}{3673} = 0.066 \\
\end{align*}

% \begin{align*}
% P(y = ham | \vec{x} = [1,0,1]) &\varpropto \frac{24}{343} = 0.070 \\ 
% P(y = ham | \vec{x} = [0,0,1]) &\varpropto \frac{2}{49} = 0.041\\
% P(y = ham | \vec{x} = [1,1,1]) &\varpropto \frac{32}{343} = 0.093\\ 
% P(y = ham | \vec{x} = [1,0,0]) &\varpropto \frac{18}{343} = 0.052\\
% P(y = ham | \vec{x} = [0,0,0]) &\varpropto \frac{3}{98} = 0.031\\
% \end{align*}

All the probabilities changed. No predictions changed.

\section*{Problem 3: Linearity of Gaussian naive Bayes}
In this question, you will show that naive Bayes is a linear classifier when using Gaussian likelihood factors with shared variances. Specifically, consider the following naive Bayes model:
$$p\left(y|x\right) = \frac{\prod^{d}_{\alpha=1}p\left(\left[x\right]_{\alpha}|y\right)p\left(y\right)}{p\left(x\right)}$$
with:
$$p\left(\left[x\right]_{\alpha}|y\right) = \mathcal{N}\left(\left[\mu_y\right]_{\alpha}, \left[\sigma\right]_{\alpha}\right)$$

That is, there is a separate mean value for each feature $\left[x\right]_{\alpha}$ and each class $y \in \{0, 1\}$. However, variances are shared across classes, so that there is only one variance $\left[\sigma\right]_{\alpha}$ per feature.
\subsection*{a)} 
Show that the decision rule $p(y=1|x)$ can equivalently be written as:
$$
p(y=1|x) = \frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)+\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}
$$
Hint: remember the sum rule and the product rule.



\textbf{Solution: } 


First, note that the numerator follows immediately from Bayes' rule, we have just substituted the actual given value $y=1$ for $y$ in the first equation in this second. For the denominator, we expand $p(x)$ using first the sum rule and the product rule. By the sum rule, $p(x)=p(x,y=1)+p(x,y=0)$. Applying the product rule to both terms on the right hand side, we get:
\begin{equation*}
	p(x) = p(x|y=1)p(y=1)+p(x|y=0)p(y=0)
\end{equation*}
Next, we apply the Naive Bayes' assumption to $p(x|y=1)$ and $p(x|y=0)$ to get:
\begin{equation*}
	p(x) = \prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)+\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)
\end{equation*}
Plugging this in for the denominator in Bayes' rule, we achieve the desired result.


\subsection*{b)}
Using this formulation, show how to rewrite $p(y=1|x)$ as:
$$
p(y=1|x) = \frac{1}{1+\exp{\left(-\log\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}\right)}}
$$


\textbf{Solution:}



Observe that, in general, $\frac{a}{a+b}$ can equivalently be written as $\frac{1}{1+\frac{b}{a}}$. Furthermore, the equation for $p(y=1|x)$ derived in the previous part has exactly the form $\frac{a}{a+b}$! Therefore, we can rewrite it as:

\begin{equation*}
	p(y=1 \mid x)=\frac{1}{1+\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}}
\end{equation*}

Next, since $\exp(\log(x))=x$,

\begin{equation*}
	p(y=1 \mid x)=\frac{1}{1+\exp\left(\log\left(\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}\right)\right)}
\end{equation*}

Finally, pulling a negative sign out of the log lets us flip the fraction inside:

\begin{equation*}
p(y=1 \mid x) = \frac{1}{1+\exp{\left(-\log\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}\right)}}
\end{equation*}

\subsection*{c)}
Given the above expression for $p(y=1|x)$, show that naive Bayes with this definition of $p([x]_{\alpha}|y)$ is a linear model. Hint: the form you derived in part b should remind you of a decision rule you have seen before.


\textbf{Solution:}


To show this, we simply plug in the following definitions to the equation we derived in part b:

\begin{align*}\
p(y=1) &= \rho \\
p([x]_{\alpha} \mid y=1)&=\frac{1}{\sqrt{2\pi[\sigma]_{\alpha}}}\exp\left(\frac{-([x]_{\alpha}-[\mu_{1}]_{\alpha})^{2}}{2[\sigma]_{\alpha}}\right) \\
p([x]_{\alpha} \mid y=0)&=\frac{1}{\sqrt{2\pi[\sigma]_{\alpha}}}\exp\left(\frac{-([x]_{\alpha}-[\mu_{0}]_{\alpha})^{2}}{2[\sigma]_{\alpha}}\right)
\end{align*}

Expanding $-\log\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)}$ we get:

\begin{equation*}
-\log p(y=1) - \log \prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1) + \log p(y=0) + \log \prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)
\end{equation*}

Observing that $\log \prod_{i} x_{i} = \sum_{i} \log x_{i}$ and rearranging terms, this is equal to:

\begin{equation*}
\log \frac{p(y=0)}{p(y=1)} + \sum_{\alpha=1}^{d} \log \frac{p([x]_{\alpha}|y=0)}{p([x]_{\alpha}|y=1)}
\end{equation*}

Plugging in the definition of $p(y=1)$, the first term in this is equal to $\log \frac{1-\rho}{\rho}$. 

For the second term, we plug in the Gaussian distributions for $p([x]_{\alpha} \mid y=1)$ and $p([x]_{\alpha} \mid y=0)$, and then do a bit of algebra to get:

\begin{equation*}
\sum_{\alpha=1}^{d} \frac{([\mu_{0}]_{\alpha}-[\mu_{1}]_{\alpha})[x]_{\alpha}}{[\sigma]_{\alpha}} + \frac{[\mu_{1}]^{2}_{\alpha}-[\mu_{0}]^{2}_{\alpha}}{2[\sigma]_{\alpha}}
\end{equation*}

Putting everything together we get:

\begin{equation*}
\log \frac{1-\rho}{\rho} + \sum_{\alpha=1}^{d} \frac{([\mu_{0}]_{\alpha}-[\mu_{1}]_{\alpha})[x]_{\alpha}}{[\sigma]_{\alpha}} + \frac{[\mu_{1}]^{2}_{\alpha}-[\mu_{0}]^{2}_{\alpha}}{2[\sigma]_{\alpha}}
\end{equation*}

And finally we just start renaming terms. Let's first define:
\begin{equation*}
b = \log \frac{1-\rho}{\rho} + \sum_{\alpha=1}^{d} \frac{[\mu_{1}]^{2}_{\alpha}-[\mu_{0}]^{2}_{\alpha}}{2[\sigma]_{\alpha}}
\end{equation*}

Next, create a vector $\mathbf{w}$ so that:
\begin{equation*}
[\mathbf{w}]_{\alpha} = \frac{[\mu_{0}]_{\alpha}-[\mu_{1}]_{\alpha}}{[\sigma]_{\alpha}}
\end{equation*}

Then the sum (the second term) is simply equal to $\mathbf{w}^{\top}x$. Therefore,

\begin{equation*}
-\log\frac{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=1)p(y=1)}{\prod_{\alpha=1}^{d} p([x]_{\alpha}|y=0)p(y=0)} = \mathbf{w}^{\top}x+b
\end{equation*}

Plugging this in to the decision rule $p(y=1|x)$ we derived in part b, we finally see that:

\begin{equation*}
	p(y=1|x) = \frac{1}{1+\exp\left(\mathbf{w}^{\top}x+b\right)}
\end{equation*}

This is not only a linear decision boundary, but should look very similar indeed to the linear decision rule you've seen from logistic regression!



\end{document}

